{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['9597' '9143' '8967' ... '1954' '9707' '6120']\n",
      "[['G' 'G' 'G' ... '?' 'T' 'A']\n",
      " ['G' 'G' 'G' ... 'A' 'T' 'A']\n",
      " ['A' 'G' 'A' ... 'A' '?' 'A']\n",
      " ...\n",
      " ['G' 'A' 'G' ... 'T' 'T' 'A']\n",
      " ['G' 'G' 'A' ... 'A' 'T' 'A']\n",
      " ['G' 'G' 'G' ... 'A' 'T' 'C']]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Read data\n",
    "\n",
    "X_train = []\n",
    "samples_x_train = []\n",
    "\n",
    "f = open(\"genotypes.csv\",\"r\")\n",
    "\n",
    "for i,line in enumerate(f):\n",
    "    if(i == 0):\n",
    "        continue\n",
    "    \n",
    "    sv = line.strip().split(\",\")\n",
    "    samples_x_train.append(sv[0])\n",
    "    \n",
    "    row = []\n",
    "    for element in sv[1:]:\n",
    "        row.append(element)\n",
    "    X_train.append(row)\n",
    "    \n",
    "f.close()\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "samples_x_train = np.array(samples_x_train)\n",
    "\n",
    "print(samples_x_train)\n",
    "print(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['9608' '9801' '9647' ... '9894' '6200' '9917']\n",
      "[53.43 58.81 53.57 ... 53.68 54.62 53.35]\n"
     ]
    }
   ],
   "source": [
    "# Read phenotype values\n",
    "\n",
    "y_train = []\n",
    "samples_y_train = []\n",
    "\n",
    "f = open(\"phenotype_values.csv\",\"r\")\n",
    "\n",
    "for i,line in enumerate(f):\n",
    "    if(i == 0):\n",
    "        continue\n",
    "    sv = line.strip().split(\",\")\n",
    "    samples_y_train.append(sv[0])\n",
    "    y_train.append(float(sv[1]))\n",
    "    \n",
    "f.close()\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "samples_y_train = np.array(samples_y_train)\n",
    "\n",
    "print (samples_y_train)\n",
    "print (y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['9419' '5913' '9953' '210' '1652' '1247' '9968' '6021' '7504' '8389'\n",
      " '9436' '8132' '1722' '7250' '7' '6197' '9602' '9737' '126' '9615' '9846'\n",
      " '9945' '5959' '9844' '9769' '5394' '7570' '5811' '2240' '5871' '9722'\n",
      " '895' '386' '2320' '9638' '9766' '544' '6192' '7213' '1404' '506' '338'\n",
      " '504' '9113' '7123' '7262' '9813' '4826' '7256' '5799' '9651' '7391'\n",
      " '9739' '5628' '8037' '340' '7298' '8337' '8218' '5760' '7073' '957'\n",
      " '1158' '1612' '9748' '9816' '9511' '7210' '5860' '1862' '5795' '6919'\n",
      " '9869' '60' '8608' '7524' '5202' '424' '2166' '9529' '9588' '8247' '1006'\n",
      " '7578' '5961' '9888' '10022' '9759' '9718' '5812' '203' '7347' '7413'\n",
      " '9909' '6918' '9353' '9386' '6092' '9728' '9927' '6110' '6237' '9672'\n",
      " '9007' '8237' '9749' '6427' '9827' '2057' '9717' '9991' '1829' '9772'\n",
      " '9973' '2370' '9885' '1363' '7479' '5722' '9321' '6046' '15591' '6126'\n",
      " '5159' '6241' '5856' '9828' '9567' '7217' '8' '8230' '5923' '5276' '5821'\n",
      " '6946' '9690' '7209' '148' '7343' '9391' '7078' '7079' '9860' '7438'\n",
      " '8796' '5776' '7062' '6806' '7475' '216' '9841' '9864' '6425' '5651'\n",
      " '5878' '8239' '6418' '8770' '9720' '7387' '9593' '997' '8285' '1799'\n",
      " '7327' '162' '5888' '9622' '6142' '6127' '5736' '5733' '5644' '6971'\n",
      " '6750' '9985' '6900' '9949' '9004' '9128' '8612' '104' '9454' '2283'\n",
      " '9095' '5822' '350' '10011' '9848' '9621' '383' '321' '242' '7515' '9754'\n",
      " '2202' '9385' '7328' '5253' '7317' '1744' '9812' '867']\n",
      "[['G' 'G' 'G' ... 'T' 'T' 'A']\n",
      " ['G' 'G' 'G' ... 'A' 'T' 'A']\n",
      " ['G' 'G' 'G' ... 'T' 'T' 'A']\n",
      " ...\n",
      " ['?' 'G' 'G' ... 'T' 'C' 'A']\n",
      " ['G' 'G' 'G' ... 'A' 'T' 'A']\n",
      " ['A' 'G' 'G' ... 'T' 'C' 'A']]\n"
     ]
    }
   ],
   "source": [
    "X_test = []\n",
    "samples_x_test=[]\n",
    "\n",
    "fd=open(\"unknown_genotypes.csv\",\"r\")\n",
    "\n",
    "for i, line in enumerate(fd):\n",
    "    if(i==0):\n",
    "        continue\n",
    "    sv=line.strip().split(\",\")\n",
    "    samples_x_test.append(sv[0])\n",
    "    row=[]\n",
    "    \n",
    "    for element in sv[1:]:\n",
    "        row.append(element)\n",
    "    X_test.append(row)\n",
    "    \n",
    "fd.close()\n",
    "X_test=np.array(X_test)\n",
    "samples_x_test=np.array(samples_x_test)\n",
    "print(samples_x_test)\n",
    "print(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['G' 'G' 'G' ... 'T' 'T' 'A']\n",
      " ['G' 'G' 'G' ... 'A' 'T' 'A']\n",
      " ['G' 'G' 'G' ... 'T' 'T' 'A']\n",
      " ...\n",
      " ['nan' 'G' 'G' ... 'T' 'C' 'A']\n",
      " ['G' 'G' 'G' ... 'A' 'T' 'A']\n",
      " ['A' 'G' 'G' ... 'T' 'C' 'A']] [['G' 'G' 'G' ... 'nan' 'T' 'A']\n",
      " ['G' 'G' 'G' ... 'A' 'T' 'A']\n",
      " ['A' 'G' 'A' ... 'A' 'nan' 'A']\n",
      " ...\n",
      " ['G' 'A' 'G' ... 'T' 'T' 'A']\n",
      " ['G' 'G' 'A' ... 'A' 'T' 'A']\n",
      " ['G' 'G' 'G' ... 'A' 'T' 'C']]\n"
     ]
    }
   ],
   "source": [
    "#Replace \"?\" with np.nan\n",
    "X_train = np.where(X_train == \"?\", np.nan, X_train)\n",
    "X_test = np.where(X_test == \"?\", np.nan, X_test)\n",
    "\n",
    "print(X_test, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ... nan  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 2.  0.  2. ...  0. nan  0.]\n",
      " ...\n",
      " [ 0.  2.  0. ...  2.  0.  0.]\n",
      " [ 0.  0.  2. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  2.]] [[ 0.  0.  0. ...  2.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  2.  0.  0.]\n",
      " ...\n",
      " [nan  0.  0. ...  2.  2.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 2.  0.  0. ...  2.  2.  0.]]\n"
     ]
    }
   ],
   "source": [
    "#Encode nucleotide values\n",
    "\n",
    "for j in range (X_train.shape[1]):\n",
    "    \n",
    "    values, counts = np.unique(X_train[:,j], return_counts=True)\n",
    "    values=values[:2]\n",
    "    counts=counts[:2]\n",
    "\n",
    "    X_train[:,j] = np.where(X_train[:,j] == values[np.argmax(counts)], 0, X_train[:,j])\n",
    "    X_train[:,j] = np.where(X_train[:,j] == values[np.argmin(counts)], 2, X_train[:,j])\n",
    "    #X_train[:,j] = np.where(X_train[:,j] == 'nan', np.nan, X_train[:,j])\n",
    "\n",
    "for j in range (X_test.shape[1]):\n",
    "    \n",
    "    values, counts = np.unique(X_test[:,j], return_counts=True)\n",
    "    \n",
    "    values=values[:2]\n",
    "    counts=counts[:2]\n",
    "    \n",
    "    X_test[:,j] = np.where(X_test[:,j] == values[np.argmax(counts)], 0, X_test[:,j])\n",
    "    X_test[:,j] = np.where(X_test[:,j] == values[np.argmin(counts)], 2, X_test[:,j])\n",
    "    X_test[:,j] = np.where(values[np.argmax(counts)]==values[np.argmin(counts)], 2, X_test[:,j])\n",
    "    \n",
    "    #X_test[:,j] = np.where(X_test[:,j] == 'nan', np.nan, X_test[:,j])\n",
    "#Convert array from string to float\n",
    "X_train = X_train.astype(np.float_)\n",
    "X_test = X_test.astype(np.float_)\n",
    "\n",
    "print(X_train,X_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Samples:\t\t 1826\n",
      "No Features:\t\t 5000\n",
      "X_train Missing Values:\t\t 10.00%\n",
      "X_test Missing Values:\t\t 10.01%\n"
     ]
    }
   ],
   "source": [
    "# General analysis data:\n",
    "\n",
    "print(\"No Samples:\\t\\t %d\" % X_train.shape[0])\n",
    "print(\"No Features:\\t\\t %d\" % X_train.shape[1])\n",
    "\n",
    "missing_train = ((np.isnan(X_train)).sum()/X_train.size*100)\n",
    "print(\"X_train Missing Values:\\t\\t %.2f%%\" % missing_train)\n",
    "\n",
    "missing_test = ((np.isnan(X_test)).sum()/X_test.size*100)\n",
    "print(\"X_test Missing Values:\\t\\t %.2f%%\" % missing_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All samples have less than 50 % missing values\n"
     ]
    }
   ],
   "source": [
    "# Assess missing values per sample\n",
    "\n",
    "\n",
    "sample_indices_to_remove = []\n",
    "for i in range(X.shape[0]):\n",
    "    missing = np.isnan(X[i,:]).sum()/X.shape[1]*100\n",
    "    if missing>50:\n",
    "        print(\"Sample %d has %.2f missing values\" % (i,missing))\n",
    "        sample_indices_to_remove.append(i)\n",
    "\n",
    "if (len(sample_indices_to_remove) == 0):\n",
    "    print(\"All samples have less than 50 % missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Samples X:\t\t1826\n",
      "No Samples y:\t\t1826\n",
      "Samples correct order:\tTrue\n"
     ]
    }
   ],
   "source": [
    "# Match genotypes with phenotype values\n",
    "truth_table = (samples_x_train[:,np.newaxis]==samples_y_train)\n",
    "ind = np.where(truth_table==True)\n",
    "\n",
    "samples_x_train = samples_x_train[ind[0]]\n",
    "samples_y_train = samples_y_train[ind[1]]\n",
    "\n",
    "X_train = X_train[ind[0],:]\n",
    "y_train = y_train[ind[1]]\n",
    "\n",
    "print(\"No Samples X:\\t\\t%d\" % X_train.shape[0])\n",
    "print(\"No Samples y:\\t\\t%d\" % y_train.shape[0])\n",
    "\n",
    "print(\"Samples correct order:\\t\" + str(np.any(samples_x_train==samples_y_train)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [2. 0. 2. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 2. 0. ... 2. 0. 0.]\n",
      " [0. 0. 2. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 2.]] [[0. 0. 0. ... 2. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 2. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 2. 2. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [2. 0. 0. ... 2. 2. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Impute missing values on training data\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "X_train = imputer.fit_transform(X_train) \n",
    "X_test = imputer.fit_transform(X_test) \n",
    "\n",
    "print(X_train,X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE (Train):\t2.80\n",
      "R2 (Train):\t0.74\n",
      "MSE (Test):\t4.50\n",
      "R2 (Test):\t0.49\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "from sklearn import linear_model\n",
    "model2=linear_model.Ridge(alpha=5000)\n",
    "model2.fit(X_train, y_train)\n",
    "predictions_training = model2.predict(X_train)\n",
    "predictions_testing = model2.predict(X_test)\n",
    "\n",
    "print(\"MSE (Train):\\t%.2f\" % metrics.mean_squared_error(y_train, predictions_training))\n",
    "print(\"R2 (Train):\\t%.2f\" % metrics.r2_score(y_train, predictions_training))\n",
    "print(\"MSE (Test):\\t%.2f\" % metrics.mean_squared_error(y_test, predictions_testing))\n",
    "print(\"R2 (Test):\\t%.2f\" % metrics.r2_score(y_test, predictions_testing))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-ebf1674d66af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0my_predictions_testing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MSE (Train):\\t%.2f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predictions_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"EV (Train):\\t %.2f\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplained_variance_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_predictions_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MAE (Train):\\t %.2f\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predictions_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'metrics' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model3=linear_model.ElasticNet(alpha=0.13135893963030046,l1_ratio=0.09,max_iter=7000)\n",
    "model3.fit(X_train, y_train)\n",
    "y_predictions_training = model3.predict(X_train)\n",
    "y_predictions_testing = model3.predict(X_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE (Train):\t0.82\n",
      "EV (Train):\t 0.92\n",
      "MAE (Train):\t 0.71\n",
      "R2 (Train):\t0.92\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-911fa98e8219>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"R2 (Train):\\t%.2f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predictions_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MSE (Test):\\t%.2f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predictions_testing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"EV (Test): \\t %.2f\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplained_variance_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_predictions_testing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MAE (Test):\\t %.2f\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predictions_testing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(\"MSE (Train):\\t%.2f\" % metrics.mean_squared_error(y_train, y_predictions_training))\n",
    "print(\"EV (Train):\\t %.2f\" %metrics.explained_variance_score(y_train,y_predictions_training))\n",
    "print(\"MAE (Train):\\t %.2f\" %metrics.mean_absolute_error(y_train, y_predictions_training))\n",
    "print(\"R2 (Train):\\t%.2f\" % metrics.r2_score(y_train, y_predictions_training))\n",
    "\n",
    "#Thes metrics have to be computed by the server\n",
    "'''\n",
    "print(\"MSE (Test):\\t%.2f\" % metrics.mean_squared_error(y_test, y_predictions_testing))\n",
    "print(\"EV (Test): \\t %.2f\" %metrics.explained_variance_score(y_test,y_predictions_testing))\n",
    "print(\"MAE (Test):\\t %.2f\" %metrics.mean_absolute_error(y_test, y_predictions_testing))\n",
    "print(\"R2 (Test):\\t%.2f\" % metrics.r2_score(y_test, y_predictions_testing))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_samples=pd.DataFrame(samples_x_test)\n",
    "df_y_pred=pd.DataFrame(y_predictions_testing)\n",
    "frames=[df_samples,df_y_pred]\n",
    "df_final=pd.concat(frames, axis=1, join='inner')\n",
    "\n",
    "df_final.to_csv(\"y_predictions.csv\",index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.94729974473867 1726 [ 0.00000000e+00 -1.26403277e-02  0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00  4.59877878e-02  1.74819276e-02\n",
      "  0.00000000e+00 -4.16598871e-03  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00  2.33003331e-02 -8.67336744e-03 -0.00000000e+00\n",
      " -0.00000000e+00  3.00966527e-02 -0.00000000e+00  0.00000000e+00\n",
      " -8.43151412e-03  4.87532209e-02 -0.00000000e+00  4.67429208e-03\n",
      " -0.00000000e+00  1.17282141e-02  5.30281563e-03 -0.00000000e+00\n",
      "  0.00000000e+00  5.85337213e-03 -0.00000000e+00  5.54044703e-03\n",
      "  0.00000000e+00 -0.00000000e+00  1.86337760e-02  8.70225884e-02\n",
      " -0.00000000e+00  8.32665335e-02 -0.00000000e+00 -6.66674319e-03\n",
      "  0.00000000e+00 -0.00000000e+00  3.51947267e-02  5.90958410e-02\n",
      " -2.24420727e-02  7.20178684e-03 -1.45471883e-02 -0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00  0.00000000e+00 -2.02659529e-02\n",
      "  0.00000000e+00 -1.77566097e-02 -0.00000000e+00 -5.28075898e-02\n",
      " -6.16714023e-03 -1.99986219e-02 -1.62911265e-02  0.00000000e+00\n",
      " -0.00000000e+00 -1.18788558e-02  4.73195158e-02 -0.00000000e+00\n",
      " -5.31093032e-03 -4.84967970e-02 -0.00000000e+00 -8.92824253e-03\n",
      " -3.73966535e-02  7.58876449e-02  0.00000000e+00  4.30196051e-02\n",
      " -0.00000000e+00  0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      "  5.95070635e-03  0.00000000e+00 -9.09944628e-02 -0.00000000e+00\n",
      " -1.73147813e-05 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00 -3.13398538e-02 -0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  8.06875578e-03 -0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -9.05242805e-02  0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00  2.53686439e-02  0.00000000e+00\n",
      "  9.50627224e-03 -3.62806357e-02  5.65997098e-02  4.44083320e-03\n",
      "  0.00000000e+00  0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00  3.13576267e-02  5.61345834e-02 ...  0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00 -0.00000000e+00 -5.30471277e-02\n",
      " -0.00000000e+00  6.90813804e-03 -0.00000000e+00  9.34399313e-03\n",
      " -4.95503972e-03  8.18343127e-02  0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00  0.00000000e+00  1.39258010e-02\n",
      "  3.87262937e-02 -6.80039688e-02  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  7.10090443e-02  0.00000000e+00  5.72446561e-02\n",
      "  0.00000000e+00 -0.00000000e+00  0.00000000e+00 -1.86882001e-02\n",
      " -0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -2.28856505e-02  3.71956616e-02 -0.00000000e+00  0.00000000e+00\n",
      " -3.56386339e-02 -3.08183652e-02  0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00  8.37127049e-03 -5.18369385e-03  4.81819354e-02\n",
      "  0.00000000e+00 -4.00827690e-03  6.83079361e-02 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00  0.00000000e+00  9.98179997e-03\n",
      " -0.00000000e+00  2.90666740e-01  0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00  1.15741781e-01\n",
      " -0.00000000e+00 -2.10994769e-03 -8.93757055e-03 -0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00  5.35166264e-02 -8.38368662e-03\n",
      "  1.04435427e-02  0.00000000e+00  2.14713585e-03 -2.37418604e-02\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      "  4.17010277e-02  7.02601924e-03  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  9.97008598e-03  3.14220890e-02  0.00000000e+00\n",
      " -0.00000000e+00 -1.50973082e-02  1.57842722e-02  8.69121900e-03\n",
      " -1.64380126e-02  0.00000000e+00 -1.57068272e-02 -0.00000000e+00\n",
      " -0.00000000e+00  8.37838092e-03  0.00000000e+00 -0.00000000e+00\n",
      " -1.10813404e-02  3.62314458e-02  0.00000000e+00  0.00000000e+00\n",
      "  6.69660407e-02 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00 -0.00000000e+00  3.68154613e-03\n",
      "  0.00000000e+00 -0.00000000e+00 -4.08108046e-02  7.32134366e-03\n",
      "  4.08087912e-02  0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      " -1.17679237e-02 -0.00000000e+00 -8.02406126e-02  5.55937990e-02\n",
      " -0.00000000e+00 -8.77253206e-02]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(edgeitems=127)\n",
    "#print(model1.intercept_,model1.coef_)\n",
    "#print(model2.intercept_,model2.coef_)\n",
    "print(model3.intercept_,model3.coef_[model3.coef_!=0].size,model3.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-3255a5ebcef3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"explained_variance\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model3' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "print(cross_val_score(model3, x, y, cv=10, scoring=\"explained_variance\").mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "610a6f344c2137faf927ea819c63f6cee33a2c04455044b28099f39fe9722347"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
